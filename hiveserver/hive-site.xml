<configuration>

  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:postgresql://postgresql:5432/metastore</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>org.postgresql.Driver</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>hive</value>
  </property>

  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>hive</value>
  </property>

  <property>
    <name>datanucleus.autoCreateSchema</name>
    <value>false</value>
  </property>

  <property>
    <name>hive.execution.engine</name>
    <value>spark</value>
  </property>

  <property>
    <name>fs.alluxio.impl</name>
    <value>alluxio.hadoop.FileSystem</value>
  </property>

  <property>
    <name>fs.defaultFS</name>
    <value>alluxio://alluxio-master:19998</value>
  </property>

  <property>
    <name>spark.master</name>
    <value>spark://spark-master:6066</value>
  </property>

  <property>
    <name>spark.eventLog.dir</name>
    <value>alluxio://alluxio-master:19998/sparkeventLog</value>
  </property>
  
  <property>
    <name>spark.home</name>
    <value>/opt/spark</value>
  </property>

  <property>
    <name>hive.server2.transport.mode</name>
    <value>http</value>
  </property>

  <property>
    <name>spark.executor.memory</name>
    <value>4g</value>
  </property>

  <property>
    <name>spark.executor.memoryOverhead</name>
    <value>384m</value>
  </property>

  <property>
    <name>spark.driver.memoryOverhead</name>
    <value>384m</value>
  </property>

  <property>
    <name>spark.scheduler.minRegisteredResourcesRatio</name>
    <value>0.8</value>
  </property>

</configuration>
